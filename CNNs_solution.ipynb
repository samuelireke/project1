{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical on Convolutional Neural Networks\n",
    "\n",
    "During this practical you will learn how to develop and train a convolutional neural network for recognising hand-written digits provided by the MNIST dataset (you can read more here:https://en.wikipedia.org/wiki/MNIST_database), using the keras library: https://keras.io/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#The dataset can be downloaded and loaded through the keras library as follows:\n",
    "#(the first time might take longer because the dataset will be downloaded first)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the data \n",
    "\n",
    "To view the four first examples of the dataset, we will you matplotlib. The command %matplotlib inline tells your jupyter notebook to show the image, if you forget it the images won't show on your browser. \n",
    "\n",
    "The cryptic arguments (2,2,1), (2,2,2), (2,2,3), and (2,2,4) below correspond to top left, top right, bottom left and bottom right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing\n",
    "\n",
    "After we load the MNIST dataset, we will need to reshape it so that it is suitable for training a CNN. \n",
    "In Keras, the layers used for two-dimensional convolutions expect pixel values with the follwong dimensions:\n",
    "\n",
    "[samples,width,height,channels]\n",
    "\n",
    "Note that because the MNIST data is in grey scale, we only have one channel, i.e the channel dimension is 1. If we had RGB images, the channels would have a value of 3, and it would be like having 3 image inputs for every color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling \n",
    "\n",
    "For grayscale images, the pixel values are between 0 and 255. When using neural networks, it is common practice to scale rhe input values by dividing each value by the maximum of 255, so they can take values between 0-1 (so they are more similar). This process is called normalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding of outputs\n",
    "\n",
    "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem (as opposed to binary that we only predict between two classes). Therefore, we will encode the outputs using one-hot encoding as follows: \n",
    "\n",
    "Digit 0 ---> [0,0,0,0,0,0,0,0,0]<br>\n",
    "Digit 1 ---> [1.0,0,0,0,0,0,0,0]<br>\n",
    "Digit 2 ---> [0,1,0,0,0,0,0,0,0]<br>\n",
    "...<br>\n",
    "Digit 9 ---> [0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining a CNN model\n",
    "\n",
    "The function below defines a sequential model (this is how keras defines a CNN). Our models has aconvolutional layer, with a filter 5x5, and ReLU as an activation function (you can define more arguments, see here: https://keras.io/layers/convolutional/). \n",
    "\n",
    "The CNN also includes a maxpooling layer with strides 2x2, a dropout layer (randomly sets a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting) and two fully-connected layers (which are denoted as Dense in keras).\n",
    "\n",
    "The model will be trained by using stochastic gradients descent (\"sgd\"), and it will use MSE as a loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #Compile/train model\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "model = cnn_model()\n",
    "model.summary()\n",
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=200)\n",
    "#Evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise(s): \n",
    "\n",
    "1. Define a new function \"deep_cnn_model\", that includes three convolutional layers, with maxpooling in between them. <br>\n",
    "2. Evaluate your model as above. Which of the two models is more accurate? <br>\n",
    "3. Finally, try changing the loss function, the optimizer, strides, epochs etc. (check keras documentation for examples). Does your model perform better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_cnn_model(): \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(30, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
